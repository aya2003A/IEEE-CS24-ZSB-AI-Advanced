{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.0-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 3.5 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     -------------------------------------- 345.4/345.4 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Collecting numpy<2,>=1.22.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     ---------------------------------------- 15.8/15.8 MB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.4\n",
      "    Uninstalling pandas-1.4.4:\n",
      "      Successfully uninstalled pandas-1.4.4\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.0 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25664</td>\n",
       "      <td>2.04978</td>\n",
       "      <td>-6.23640</td>\n",
       "      <td>4.71926</td>\n",
       "      <td>-4.26931</td>\n",
       "      <td>0.20590</td>\n",
       "      <td>12.31798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.89012</td>\n",
       "      <td>-0.37511</td>\n",
       "      <td>6.14979</td>\n",
       "      <td>4.94585</td>\n",
       "      <td>-3.57844</td>\n",
       "      <td>0.00640</td>\n",
       "      <td>23.67628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.09784</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>5.85805</td>\n",
       "      <td>0.28297</td>\n",
       "      <td>-0.20626</td>\n",
       "      <td>-1.53459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.39034</td>\n",
       "      <td>-3.06861</td>\n",
       "      <td>-5.63488</td>\n",
       "      <td>6.43941</td>\n",
       "      <td>0.39256</td>\n",
       "      <td>-0.07084</td>\n",
       "      <td>-24.68670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.84727</td>\n",
       "      <td>-0.15922</td>\n",
       "      <td>11.41246</td>\n",
       "      <td>7.52165</td>\n",
       "      <td>1.69886</td>\n",
       "      <td>0.29022</td>\n",
       "      <td>17.54122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1         2        3        4        5         6\n",
       "0  1.25664  2.04978  -6.23640  4.71926 -4.26931  0.20590  12.31798\n",
       "1 -3.89012 -0.37511   6.14979  4.94585 -3.57844  0.00640  23.67628\n",
       "2  5.09784  0.98120  -0.29939  5.85805  0.28297 -0.20626  -1.53459\n",
       "3  0.39034 -3.06861  -5.63488  6.43941  0.39256 -0.07084 -24.68670\n",
       "4  5.84727 -0.15922  11.41246  7.52165  1.69886  0.29022  17.54122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read our data from csv file\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from Pandas dataframe\n",
    "X = data.loc[:,0:1]\n",
    "y = data.loc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset to Numpy\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to make a prediction\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "     for i in range(len(X)):\n",
    "        y_hat = sum(X[i] * W) + b\n",
    "\n",
    "        if (y[i] == 1 and y_hat < 0) or (y[i] == 0 and y_hat >= 0):\n",
    "            W = [W[j] + learn_rate * X[i][j] * y[i] for j in range(len(W))]\n",
    "            b = b + learn_rate * y[i] \n",
    "\n",
    "     return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate=0.01, num_epochs=25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    \n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step to update W & b\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        \n",
    "        print(f\"Training epoch: #{i+1}\")\n",
    "        print(f\"Weight: {W}\")\n",
    "        print(f\"bias: {b}\")\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: #1\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #2\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #3\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #4\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #5\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #6\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #7\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #8\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #9\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n",
      "Training epoch: #10\n",
      "Weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.37454012],\n",
       "        [0.95071431]]),\n",
       " 14.106533941811405)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "model_train = trainPerceptronAlgorithm(X, y, \n",
    "                                 learn_rate=0.001, \n",
    "                                 num_epochs=10)\n",
    "model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[0.37454012]\n",
      " [0.95071431]]\n",
      "bias: 14.106533941811405\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction from the model training\n",
    "final_model = model_train\n",
    "weight, bias = final_model\n",
    "\n",
    "print(f\"weight: {weight}\")\n",
    "print(f\"bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(X=[-1, 0.5], W=weight, b=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
